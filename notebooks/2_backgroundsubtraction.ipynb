{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Background Subtraction\n",
    "\n",
    "One way to detect movements in a video is to use background subtraction. There are different types of background subtraction algorithm, and each algorithm has various, different parameters. \n",
    "\n",
    "This notebook introduces some of background subtractors that are implemented in Birdwatcher, which are based on OpenCV. It shows how to access them, how to check out the various parameters they have, and how they are used for movement detection. Much of what's in here is encaspulated by higher-order functions or classes, but if you want to have full control over things, or better understand what's happening under the hood, have a look at the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import birdwatcher as bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a video object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vfs = bw.VideoFileStream(r'..\\videos\\zf20s_low.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a background subtractor object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a background subtractor object with default parameters. This object basically encapsulates the algorithm that determines the background from a history of images, and uses that to find what is not background in the current image. See opencv page for more info on the algorithm: https://docs.opencv.org/3.4/d7/d7b/classcv_1_1BackgroundSubtractorMOG2.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgs = bw.BackgroundSubtractorMOG2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are its parameters? In this case all default, because we didn't specify any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgs.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the docstrings, you can see the definition of each parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw.BackgroundSubtractorMOG2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use non-default parameters by specifying them at intstantiation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgs = bw.BackgroundSubtractorMOG2(VarThreshold=50, NMixtures=8, History=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgs.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply background subtractor to video Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be done by setting up a pipeline that generates and processes image sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, set up a frame generator that produces gray frames from the color video file object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = vfs.iter_frames(color=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, apply to the frames the background subtractor that we created above. It returns another frame generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = frames.apply_backgroundsegmenter(bgs, learningRate=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a frame generator that produces foreground mask frames. Let's get rid of some noise. (Look at MorphologyEx page of opencv for what this does: https://docs.opencv.org/3.4/d9/d61/tutorial_py_morphological_ops.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = frames.morphologyex(morphtype='open', kernelsize=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, none of the methods have actually been run over the frames yet. We just set up a processing pipeline that will run special methods, such as `to video`, which writes the end result to a videofile.\n",
    "\n",
    "So let's start running the whole pipeline and save results as a video for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = frames.tovideo('output/test_MOG2.mp4', framerate=vfs.avgframerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The creation of the whole pipeline above can also be shortened like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = (vfs.iter_frames(color=False)\n",
    "          .apply_backgroundsegmenter(bgs, learningRate=-1)\n",
    "          .morphologyex(morphtype='open', kernelsize=2)\n",
    "          .tovideo('output/test_MOG2.mp4', framerate=vfs.avgframerate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's another example of a pipeline. We have added a blur manipulation to the videoframes before appying the background segmenter. Also, we have added a region of interest (roi) that tells the background segmenter to only consider pixels within the specified rectangle in the vieo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = (vfs.iter_frames(color=False)\n",
    "          .blur((10,10))\n",
    "          .apply_backgroundsegmenter(bgs, learningRate=-1, roi=(10, 570, 10, 1250))\n",
    "          .morphologyex(morphtype='open', kernelsize=2)\n",
    "          .tovideo('output/test2_MOG2.mp4', framerate=vfs.avgframerate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a coordinate array for reliable storage of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration purposes, we wrote the movement detection results (suprathreshold pixels) above to a video file. However, most video formats are not lossy and cannot always be read efficiently and reliably. Normally you want to save the results for further analyses in a way that is better suited for scientific analyses. We save non-zero pixel (i.e. foreground) coordinates to a `CoordinateArrays` object, including some metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "coordsarray = (vfs.iter_frames(color=False)\n",
    "               .apply_backgroundsegmenter(bgs, learningRate=-1)\n",
    "               .morphologyex(morphtype='open', kernelsize=2)\n",
    "               .save_nonzero(filepath='output/testcoordsMOG.darr',\n",
    "                             metadata={'bgsparams': bgs.get_params(),\n",
    "                                       'morphologyex': ('open', 2),\n",
    "                                       'learningrate': -1,\n",
    "                                       'avgframerate': vfs.avgframerate},\n",
    "                             ignore_firstnframes=10,\n",
    "                             overwrite=True))\n",
    "\n",
    "coordsarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on `CoordinateArrays`, and how to access and view the them, just take a look at the next notebook. Basically it is a disk-based numpy-like array that you can index to retrieve the positive pixel coordinates of frames. E.g., let's  find out which pixels were positive in frame 49:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordsarray[49]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A different algorithm: KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a different algorithm for background segmentation: KNN.  See opencv page for more info on the algorithm: https://docs.opencv.org/3.4/db/d88/classcv_1_1BackgroundSubtractorKNN.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgs = bw.BackgroundSubtractorKNN()\n",
    "bgs.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A different background algorithm with different parameters. You can change these parameters the same way as in the example above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgs = bw.BackgroundSubtractorKNN(kNNSamples=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run the whole pipeline again with the other background subtractor, and save the results as video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = (vfs.iter_frames(color=False)\n",
    "          .apply_backgroundsegmenter(bgs, learningRate=-1)\n",
    "          .morphologyex(morphtype='open', kernelsize=2)\n",
    "          .tovideo('output/test_KNN.mp4', framerate=vfs.avgframerate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yet another algorithm: LSBP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.opencv.org/3.4/de/d4c/classcv_1_1bgsegm_1_1BackgroundSubtractorLSBP.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgs = bw.BackgroundSubtractorLSBP()\n",
    "bgs.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgs = bw.BackgroundSubtractorLSBP(nSamples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = (vfs.iter_frames(color=False)\n",
    "          .apply_backgroundsegmenter(bgs, learningRate=-1)\n",
    "          .morphologyex(morphtype='open', kernelsize=2)\n",
    "          .tovideo('output/test_LSBP.mp4', framerate=vfs.avgframerate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
