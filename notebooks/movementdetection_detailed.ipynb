{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows the basic steps that are involved in movement detection. Much of what's in here can be encaspulated by higher-order functions or classes, but if you want to have full control over things, have a look at the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import birdwatcher as bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a background subtractor object with suitable parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a background subtractor object with default parameters. This object basically encapsulates the algorithm that determines the background from a history of images, and uses that to find what is not background in the current image. See opencv page for more info on the algorithm: https://docs.opencv.org/3.4/d7/d7b/classcv_1_1BackgroundSubtractorMOG2.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgs = bw.BackgroundSubtractorMOG2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgs.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use non-default paramaters by specifying them at intstantiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgs = bw.BackgroundSubtractorMOG2(VarThreshold=70, NMixtures=8, History=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgs.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a video object (see separate notebook on this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf = bw.testvideosmall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do movement detection by hand based on this background subtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be done by setting up a pipe line that generates and processes image sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First set up a frame generator that produces gray frames from the color video file object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = vf.iter_frames(color=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now feed that to the background subtractor that we created above. It returns another frame generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = bgs.iter_apply(frames, learningRate=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a frame generator that produces foreground mask frames. Let's get rid of some noise. (look at MorphologyEx page of opencv for what this does: https://docs.opencv.org/3.4/d9/d61/tutorial_py_morphological_ops.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = frames.morphologyex(morphtype='open', kernelsize=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to start running the whole frame pipe line and save results as a video for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = frames.tovideo('output/test_MOG2.mp4', framerate=vf.avgframerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This whole pipeline can also be shortened like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = (bgs.iter_apply(vf.iter_frames(color=False), learningRate=-1)\n",
    "                        .morphologyex(morphtype='open', kernelsize=2)\n",
    "                        .tovideo('output/test_MOG2.mp4', framerate=vf.avgframerate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a coordinate array for storage of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wrote the movement detection results (suprathreshold pixels) above to a video so that we could view the results. However, if you want to save the results for further analyses it is much better to save tham as a *coordinate array*.\n",
    "\n",
    "A coordinate array really is just a Darr ragged array (see separate library). This makes it easy to read the data in other environments, e.g. R. We save some metadata so that we later know what we did. Instead of saving the frames to video, we now detect non-zero pixel (i.e. foreground) coordinates, and save that to the coordinate array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First set up analysis pipe line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = (bgs.iter_apply(vf.iter_frames(color=False), learningRate=-1)\n",
    "                             .morphologyex(morphtype='open', kernelsize=2)\n",
    "                             .find_nonzero())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an empty CoordinateArray object to save to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordsarray = bw.create_coordarray('output/testcoords.darr', \n",
    "                                   framewidth=vf.framewidth,\n",
    "                                   frameheight=vf.frameheight,\n",
    "                                   metadata={'bgsparams': bgs.get_params(),\n",
    "                                             'morphologyex': ('open', 2),\n",
    "                                             'learningrate': -1}, \n",
    "                                   overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordsarray.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now save pipeline to array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for c in coordinates:\n",
    "    coordsarray.append(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing coordinate arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coordinate array can be accessed in other python sessions like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordsarray = bw.CoordinateArrays('output/testcoords.darr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordsarray[100] # coordinates of the 101th frame "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take it together and look at a range of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example we'll look at a range of history settings. Note that we do not have to run the analysis pipe line twice in order to get both coordinate results and a video. We just create a coordinate array first. This can then be saved as a video for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vf = bw.testvideosmall()\n",
    "for history in (2,3,4):\n",
    "    bgs = bw.BackgroundSubtractorMOG2(History=history, VarThreshold=50)\n",
    "    coordinates = (bgs.iter_apply(vf.iter_frames(color=False), learningRate=-1)\n",
    "                         .morphologyex(morphtype='open', kernelsize=2)\n",
    "                         .find_nonzero())\n",
    "    basefilename = f'testcoords_hist{history}'\n",
    "    coordsarray = bw.create_coordarray(f'output/{basefilename}.darr', \n",
    "                                       framewidth=vf.framewidth,\n",
    "                                       frameheight=vf.frameheight, \n",
    "                                       metadata={'bgsparams': bgs.get_params(),\n",
    "                                                 'morphologyex': ('open', 2),\n",
    "                                                 'learningrate': -1}, \n",
    "                                       overwrite=True)\n",
    "    for c in coordinates:\n",
    "        coordsarray.append(c)\n",
    "    coordsarray.tovideo(f'output/{basefilename}.mp4', framerate=vf.avgframerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
