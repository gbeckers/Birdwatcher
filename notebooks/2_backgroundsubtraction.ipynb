{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To detect movements in a video, we use background subtraction. There are many different background subtraction algorithms, and each algorithm has various parameters. You can use the default parameter settings in Birdwatcher, but you can also modify the parameters.\n",
    "\n",
    "This notebook introduces some of background subtractors that are implemented in Birdwatcher. How to access them, and look at the various parameters they have. And how they are used for movement detection. Much of what's in here can be encaspulated by higher-order functions or classes, but if you want to have full control over things, have a look at the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import birdwatcher as bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a video object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vfs = bw.VideoFileStream(r'..\\videos\\zf20s_low.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a background subtractor object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a background subtractor object with default parameters. This object basically encapsulates the algorithm that determines the background from a history of images, and uses that to find what is not background in the current image. See opencv page for more info on the algorithm: https://docs.opencv.org/3.4/d7/d7b/classcv_1_1BackgroundSubtractorMOG2.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgs = bw.BackgroundSubtractorMOG2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgs.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the docstrings, you can see the definition of each parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw.BackgroundSubtractorMOG2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use non-default parameters by specifying them at intstantiation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgs = bw.BackgroundSubtractorMOG2(VarThreshold=50, NMixtures=8, History=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgs.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply background subtractor to video Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be done by setting up a pipeline that generates and processes image sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, set up a frame generator that produces gray frames from the color video file object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = vfs.iter_frames(color=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, apply the background subtractor that we created above. It returns another frame generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = frames.apply_backgroundsegmenter(bgs, learningRate=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a frame generator that produces foreground mask frames. Let's get rid of some noise. (Look at MorphologyEx page of opencv for what this does: https://docs.opencv.org/3.4/d9/d61/tutorial_py_morphological_ops.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = frames.morphologyex(morphtype='open', kernelsize=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to start running the whole frame pipeline and save results as a video for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = frames.tovideo('output/test_MOG2.mp4', framerate=vfs.avgframerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This whole pipeline can also be shortened like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = (vfs.iter_frames(color=False)\n",
    "          .apply_backgroundsegmenter(bgs, learningRate=-1)\n",
    "          .morphologyex(morphtype='open', kernelsize=2)\n",
    "          .tovideo('output/test_MOG2.mp4', framerate=vfs.avgframerate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's another example of a pipeline. We have added a blur manipulation to the videoframes before appying the background segmenter. Also, we have added a region of interest (roi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = (vfs.iter_frames(color=False)\n",
    "          .blur((10,10))\n",
    "          .apply_backgroundsegmenter(bgs, learningRate=-1, roi=(10, 570, 10, 1250))\n",
    "          .morphologyex(morphtype='open', kernelsize=2)\n",
    "          .tovideo('output/test2_MOG2.mp4', framerate=vfs.avgframerate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a coordinate array for storage of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wrote the movement detection results (suprathreshold pixels) above to a video so that we could view the results. However, if you want to save the results for further analyses, it is much better to detect non-zero pixel (i.e. foreground) coordinates, and save that to a `CoordinateArrays`. We also save some metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "coordsarray = (vfs.iter_frames(color=False)\n",
    "               .apply_backgroundsegmenter(bgs, learningRate=-1)\n",
    "               .morphologyex(morphtype='open', kernelsize=2)\n",
    "               .save_nonzero(filepath='output/testcoordsMOG.darr',\n",
    "                             metadata={'bgsparams': bgs.get_params(),\n",
    "                                       'morphologyex': ('open', 2),\n",
    "                                       'learningrate': -1,\n",
    "                                       'avgframerate': vfs.avgframerate},\n",
    "                             ignore_firstnframes=10,\n",
    "                             overwrite=True))\n",
    "\n",
    "coordsarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on `CoordinateArrays`, and how to access and view the them, just take a look at the next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A different algorithm: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgs = bw.BackgroundSubtractorKNN()\n",
    "bgs.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A different background algorithm with different parameters. You can change these parameters the same way as in the example above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgs = bw.BackgroundSubtractorKNN(kNNSamples=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run the whole pipeline again with the other background subtractor, and save the results as video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = (vfs.iter_frames(color=False)\n",
    "          .apply_backgroundsegmenter(bgs, learningRate=-1)\n",
    "          .morphologyex(morphtype='open', kernelsize=2)\n",
    "          .tovideo('output/test_KNN.mp4', framerate=vfs.avgframerate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yet another algorithm: LSBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgs = bw.BackgroundSubtractorLSBP()\n",
    "bgs.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgs = bw.BackgroundSubtractorLSBP(nSamples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = (vfs.iter_frames(color=False)\n",
    "          .apply_backgroundsegmenter(bgs, learningRate=-1)\n",
    "          .morphologyex(morphtype='open', kernelsize=2)\n",
    "          .tovideo('output/test_LSBP.mp4', framerate=vfs.avgframerate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
